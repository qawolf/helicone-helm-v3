aiGateway:
  enabled: true
  image:
    repository: helicone/ai-gateway
    pullPolicy: IfNotPresent
    tag: "sha-485fd7c"
  replicaCount: 2

  serviceAccount:
    enabled: true
    name: "helicone-us-east-1-ai-gateway-sa"
    annotations: {}

  podAnnotations: {}

  # TODO: add canaries or blue-green
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%
  progressDeadlineSeconds: 90
  service:
    annotations: {}
    type: NodePort
    port: 8080
  ingress:
    enabled: true
    className: "alb"
    annotations:
      alb.ingress.kubernetes.io/load-balancer-name: "helicone-ai-gateway-alb"
      alb.ingress.kubernetes.io/scheme: "internal"
      alb.ingress.kubernetes.io/target-type: "ip"
      alb.ingress.kubernetes.io/healthcheck-path: "/health"
      alb.ingress.kubernetes.io/healthcheck-protocol: "HTTP"
      alb.ingress.kubernetes.io/healthcheck-port: "traffic-port"
      alb.ingress.kubernetes.io/healthcheck-interval-seconds: "15"
      alb.ingress.kubernetes.io/healthcheck-timeout-seconds: "5"
      alb.ingress.kubernetes.io/healthy-threshold-count: "2"
      alb.ingress.kubernetes.io/unhealthy-threshold-count: "5"
      alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS": 443}]'
      alb.ingress.kubernetes.io/backend-protocol: "HTTP"
      alb.ingress.kubernetes.io/group.name: "helicone-alb-group"
      alb.ingress.kubernetes.io/ssl-redirect: "443"
      alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=300,routing.http2.enabled=true
      alb.ingress.kubernetes.io/tags: Environment=production,Purpose=GlobalAccelerator
    hosts:
      - host: ai-gateway.helicone.ai
        paths:
          - path: /
            pathType: Prefix
    tls:
      - hosts:
          - helicone.ai
        # secretName: helicone-ai-gateway-tls # Optional: if using Kubernetes secret instead of ACM
  resources:
    requests:
      cpu: 500m
      memory: 128Mi
    limits:
      cpu: 1024m
      memory: 1024Mi

  # Health Probes Configuration
  livenessProbe:
    enabled: true
    httpGet:
      path: /health
      port: http
      scheme: HTTP
    initialDelaySeconds: 30
    periodSeconds: 15
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 1

  readinessProbe:
    enabled: true
    httpGet:
      path: /health
      port: http
      scheme: HTTP
    initialDelaySeconds: 30
    periodSeconds: 15
    timeoutSeconds: 3
    failureThreshold: 3
    successThreshold: 1

  startupProbe:
    enabled: true
    httpGet:
      path: /health
      port: http
      scheme: HTTP
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 20
    successThreshold: 1

  # Horizontal Pod Autoscaler Configuration
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
    behavior:
      scaleUp:
        stabilizationWindowSeconds: 120
        percent: 100
        pods: 2
        periodSeconds: 140
      scaleDown:
        stabilizationWindowSeconds: 180
        pods: 1
        periodSeconds: 60

  config:
    telemetry:
      level: "info,ai_gateway=trace"
      format: "compact"
      exporter: both
      otlp-endpoint: "http://otel-collector.helicone-observability.svc.cluster.local:4317/v1/metrics"

    helicone:
      features: all

    minio:
      bucket-name: "request-response-storage"
      region: "us-west-2"
      host: "https://s3.us-west-2.amazonaws.com"

    cache-store:
      type: redis
      host-url: "rediss://helicone-valkey-cache-us-east-1-t4dz5b.serverless.use1.cache.amazonaws.com"

    rate-limit-store:
      type: redis
      host-url: "rediss://helicone-valkey-cache-us-east-1-t4dz5b.serverless.use1.cache.amazonaws.com"

    deployment-target:
      type: cloud